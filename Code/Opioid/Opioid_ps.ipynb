{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opioid\n",
    "***\n",
    "Model based off the prescription opioid crisis in the United States. Based off a paper from the University of Tennessee https://0afa17f2-bd49-4985-b62b-358fb4a6bf3f.filesusr.com/ugd/f70b03_22c7703e4a3b4da6b9555c738ed8566d.pdf\n",
    "***\n",
    "## Setup the Environment\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MatPlotLib and Plotly are used for creating custom visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import iplot\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gillespy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client\n",
    "from distributed.diagnostics.progressbar import progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/distributed/dashboard/core.py:20: UserWarning:\n",
      "\n",
      "\n",
      "Dask needs bokeh >= 2.4.2, < 3 for the dashboard.\n",
      "You have bokeh==3.0.3.\n",
      "Continuing without the dashboard.\n",
      "\n",
      "2023-04-27 12:01:12,561 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "2023-04-27 12:01:12,567 - distributed.scheduler - INFO - State start\n",
      "2023-04-27 12:01:12,573 - distributed.scheduler - INFO -   Scheduler at:     tcp://127.0.0.1:40471\n",
      "2023-04-27 12:01:12,574 - distributed.scheduler - INFO -   dashboard at:            127.0.0.1:8787\n",
      "2023-04-27 12:01:12,636 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44709'\n",
      "2023-04-27 12:01:12,650 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46517'\n",
      "2023-04-27 12:01:12,666 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46481'\n",
      "2023-04-27 12:01:12,672 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37199'\n",
      "2023-04-27 12:01:13,208 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-6a2569ew', purging\n",
      "2023-04-27 12:01:13,208 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-36uq8xrz', purging\n",
      "2023-04-27 12:01:13,209 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-jmn_6z4k', purging\n",
      "2023-04-27 12:01:13,209 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x8u7bpm1', purging\n",
      "2023-04-27 12:01:13,472 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44621', name: 1, status: init, memory: 0, processing: 0>\n",
      "2023-04-27 12:01:13,721 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44621\n",
      "2023-04-27 12:01:13,722 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56818\n",
      "2023-04-27 12:01:13,726 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38051', name: 0, status: init, memory: 0, processing: 0>\n",
      "2023-04-27 12:01:13,728 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38051\n",
      "2023-04-27 12:01:13,729 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56832\n",
      "2023-04-27 12:01:13,731 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39145', name: 2, status: init, memory: 0, processing: 0>\n",
      "2023-04-27 12:01:13,735 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39145\n",
      "2023-04-27 12:01:13,736 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56836\n",
      "2023-04-27 12:01:13,738 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39979', name: 3, status: init, memory: 0, processing: 0>\n",
      "2023-04-27 12:01:13,741 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39979\n",
      "2023-04-27 12:01:13,742 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56850\n",
      "2023-04-27 12:01:13,792 - distributed.scheduler - INFO - Receive client connection: Client-351f4131-e4f3-11ed-9473-c97d32debf0a\n",
      "2023-04-27 12:01:13,794 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:56862\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "os.environ['MALLOC_TRIM_THRESHOLD_'] = '8192'\n",
    "\n",
    "cluster = LocalCluster(n_workers=4, nanny=True)\n",
    "client = Client(cluster)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Create the Opioid Model\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_opioid(t):\n",
    "    model = gillespy2.Model(name='Opioid')\n",
    "    model.volume = 1\n",
    "\n",
    "    # Variables\n",
    "    Susceptible = gillespy2.Species(name='Susceptible', initial_value=1000, mode='discrete')\n",
    "    Prescribed_User = gillespy2.Species(name='Prescribed_User', initial_value=0, mode='discrete')\n",
    "    Addicted = gillespy2.Species(name='Addicted', initial_value=0, mode='discrete')\n",
    "    Rehab = gillespy2.Species(name='Rehab', initial_value=0, mode='discrete')\n",
    "    Natural_Deaths = gillespy2.Species(name='Natural_Deaths', initial_value=0, mode='discrete')\n",
    "    Addicted_Deaths = gillespy2.Species(name='Addicted_Deaths', initial_value=0, mode='discrete')\n",
    "    model.add_species([\n",
    "        Susceptible, Prescribed_User, Addicted, Rehab, Natural_Deaths, Addicted_Deaths\n",
    "    ])\n",
    "\n",
    "    # Parameters\n",
    "    alpha = gillespy2.Parameter(name='alpha', expression='0.15')\n",
    "    epsilon = gillespy2.Parameter(name='epsilon', expression='0.8')\n",
    "    beta_p = gillespy2.Parameter(name='beta_p', expression='0.00266')\n",
    "    beta_a = gillespy2.Parameter(name='beta_a', expression='0.00094')\n",
    "    gamma = gillespy2.Parameter(name='gamma', expression='0.00744')\n",
    "    zeta = gillespy2.Parameter(name='zeta', expression='0.2')\n",
    "    delta = gillespy2.Parameter(name='delta', expression='0.1')\n",
    "    sigma = gillespy2.Parameter(name='sigma', expression='0.9')\n",
    "    mu = gillespy2.Parameter(name='mu', expression='0.00729')\n",
    "    mu_prime = gillespy2.Parameter(name='mu_prime', expression='0.01159')\n",
    "    model.add_parameter([\n",
    "        alpha, epsilon, beta_p, beta_a, gamma, zeta, delta, sigma, mu, mu_prime\n",
    "    ])\n",
    "\n",
    "    # Reactions\n",
    "    SP = gillespy2.Reaction(\n",
    "        name='SP', rate='alpha',\n",
    "        reactants={'Susceptible': 1}, products={'Prescribed_User': 1}\n",
    "    )\n",
    "    SA_a = gillespy2.Reaction(\n",
    "        name='SA_a', rate='beta_a',\n",
    "        reactants={'Susceptible': 1}, products={'Addicted': 1}\n",
    "    )\n",
    "    SA_p = gillespy2.Reaction(\n",
    "        name='SA_p', rate='beta_p',\n",
    "        reactants={'Susceptible': 1}, products={'Addicted': 1}\n",
    "    )\n",
    "    PA = gillespy2.Reaction(\n",
    "        name='PA', rate='gamma',\n",
    "        reactants={'Prescribed_User': 1}, products={'Addicted': 1}\n",
    "    )\n",
    "    PS = gillespy2.Reaction(\n",
    "        name='PS', rate='epsilon',\n",
    "        reactants={'Prescribed_User': 1}, products={'Susceptible': 1}\n",
    "    )\n",
    "    AR = gillespy2.Reaction(\n",
    "        name='AR', rate='zeta',\n",
    "        reactants={'Addicted': 1}, products={'Rehab': 1}\n",
    "    )\n",
    "    RA = gillespy2.Reaction(\n",
    "        name='RA', rate='delta',\n",
    "        reactants={'Rehab': 1}, products={'Addicted': 1}\n",
    "    )\n",
    "    RS = gillespy2.Reaction(\n",
    "        name='RS', rate='sigma',\n",
    "        reactants={'Rehab': 1}, products={'Susceptible': 1}\n",
    "    )\n",
    "    mu_S = gillespy2.Reaction(\n",
    "        name='mu_S', rate='mu',\n",
    "        reactants={'Susceptible': 1}, products={'Susceptible': 1, 'Natural_Deaths': 1}\n",
    "    )\n",
    "    mu_P = gillespy2.Reaction(\n",
    "        name='mu_P', rate='mu',\n",
    "        reactants={'Prescribed_User': 1}, products={'Susceptible': 1, 'Natural_Deaths': 1}\n",
    "    )\n",
    "    mu_R = gillespy2.Reaction(\n",
    "        name='mu_R', rate='mu',\n",
    "        reactants={'Rehab': 1}, products={'Susceptible': 1, 'Natural_Deaths': 1}\n",
    "    )\n",
    "    mu_prime_A = gillespy2.Reaction(\n",
    "        name='mu_prime_A', rate='mu_prime',\n",
    "        reactants={'Addicted': 1}, products={'Susceptible': 1, 'Addicted_Deaths': 1}\n",
    "    )\n",
    "    model.add_reaction([\n",
    "        SP, SA_a, SA_p, PA, PS, AR, RA, RS, mu_S, mu_P, mu_R, mu_prime_A\n",
    "    ])\n",
    "\n",
    "    # Timespan\n",
    "    #tspan = gillespy2.TimeSpan.arange(1, t=200)\n",
    "    tspan = gillespy2.TimeSpan.arange(1, t)\n",
    "    model.timespan(tspan)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Simulation Parameters\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_simulation(model, n):\n",
    "    solver = gillespy2.SSACSolver(model=model, delete_directory=False)\n",
    "    kwargs = {\n",
    "        'number_of_trajectories': n,\n",
    "        'timeout':20,\n",
    "        # 'seed': None,\n",
    "        # 'tau_tol': 0.03,\n",
    "        # 'integrator_options': {'rtol': 0.001, 'atol': 1e-06},\n",
    "        'solver': solver,\n",
    "    }\n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Parameter Sweep\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParameterSweep:\n",
    "    def __init__(self, t, kwargs, model):\n",
    "        self.tspan = t\n",
    "        self.model = model\n",
    "        self.settings = {}\n",
    "        self.parameters = []\n",
    "        self.__parameters = {}\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "        self.results = {}\n",
    "        self.__results = {}\n",
    "\n",
    "    def __reset(self):\n",
    "        self.results = {}\n",
    "        self.__results = {}\n",
    "        \n",
    "    def __write_to_file(self, filename):\n",
    "        with open(filename, 'a', encoding='UTF8', newline = \"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            row = []\n",
    "            row.append(self.runtime)\n",
    "            paras = ['alpha', 'epsilon', 'beta_p', 'beta_a', 'gamma', 'zeta', 'delta', 'sigma', 'mu', 'mu_prime']\n",
    "            #paras = ['alpha', 'epsilon']\n",
    "            for para in paras:\n",
    "                row.append(self.settings[\"variables\"][para])\n",
    "            row.append(self.settings[\"number_of_trajectories\"])\n",
    "            row.append(self.tspan)\n",
    "            writer.writerow(row)\n",
    "  \n",
    "    def __run(self, variables, index, verbose=False):\n",
    "        if index < len(self.parameters):\n",
    "            parameter = self.parameters[index]\n",
    "            index += 1\n",
    "            for value in parameter['range']:\n",
    "                variables[parameter['param']] = value\n",
    "                self.__run(variables, index, verbose=verbose)\n",
    "        else:\n",
    "            start = time.time()\n",
    "            sim_key = hashlib.md5(str(variables).encode('utf-8')).hexdigest()\n",
    "            if sim_key not in self.results:\n",
    "                model = self.__setup_model(variables=variables)\n",
    "                if verbose:\n",
    "                    print(f'--> running: {str(variables)}')\n",
    "                self.results[sim_key] = model.run(**self.settings)\n",
    "            end = time.time()\n",
    "            self.runtime = end - start\n",
    "            self.__write_to_file(\"opioid_data.csv\")\n",
    "            #print(self.settings[\"variables\"])\n",
    "            #print(self.settings)\n",
    "\n",
    "    def __resume(self, resume):\n",
    "        orig_params = {}\n",
    "        self.results = resume.data\n",
    "        for parameter in resume.parameters:\n",
    "            orig_params[parameter['param']] = parameter['range']\n",
    "            self.add_parameter(parameter['param'], values= parameter['range'])\n",
    "        new_params = [param for param in self.__parameters if param not in orig_params]\n",
    "        if len(new_params) > 0:\n",
    "            variables = {new_param: self.model.listOfParameters[new_param].value for new_param in new_params}\n",
    "            self.__update_results(resume.parameters, variables, {})\n",
    "            self.results = self.__results\n",
    "\n",
    "    def __setup_model(self, variables):\n",
    "        if 'solver' in self.settings and 'CSolver' in self.settings['solver'].name:\n",
    "            self.settings['variables'] = copy.deepcopy(variables)\n",
    "            return self.model\n",
    "        model = copy.deepcopy(self.model)\n",
    "        for name, value in variables.items():\n",
    "            model.listOfParameters[name].expression = str(value)\n",
    "        return model\n",
    "\n",
    "    def __update_results(self, parameters, variables, orig_vars, index=0):\n",
    "        if index < len(parameters):\n",
    "            parameter = parameters[index]\n",
    "            index += 1\n",
    "            for value in parameter['range']:\n",
    "                orig_vars[parameter['param']] = value\n",
    "                variables[parameter['param']] = value\n",
    "                self.__update_results(parameters, variables, orig_vars, index=index)\n",
    "        else:\n",
    "            o_sim_key = hashlib.md5(str(orig_vars).encode('utf-8')).hexdigest()\n",
    "            n_sim_key = hashlib.md5(str(variables).encode('utf-8')).hexdigest()\n",
    "            self.__results[n_sim_key] = self.results[o_sim_key]\n",
    "\n",
    "    def add_parameter(self, param, bounds=None, steps=11, values=None):\n",
    "        if values is None:\n",
    "            values = numpy.linspace(bounds[0], bounds[1], steps)\n",
    "        else:\n",
    "            values = numpy.array(values)\n",
    "        if param in self.__parameters:\n",
    "            for value in values:\n",
    "                if value not in self.__parameters[param]:\n",
    "                    self.__parameters[param] = numpy.append(self.__parameters[param], value)\n",
    "            self.__parameters[param] = numpy.sort(self.__parameters[param])\n",
    "        else:\n",
    "            self.__parameters[param] = values\n",
    "        self.parameters = [{'param': param, 'range': ps_range} for param, ps_range in self.__parameters.items()]\n",
    "\n",
    "    def run(self, resume=None, verbose=False):\n",
    "        self.settings = self.kwargs\n",
    "\n",
    "        if resume is not None:\n",
    "            self.__resume(resume)\n",
    "        index = 0\n",
    "        variables = {}\n",
    "        self.timeout = self.settings[\"timeout\"]\n",
    "        self.__run(variables, index, verbose=verbose)\n",
    "\n",
    "        results = Results(self.results, self.parameters)\n",
    "        self.__reset()\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Results:\n",
    "    func_map = {\n",
    "        'min': numpy.min, 'max': numpy.max, 'avg': numpy.mean,\n",
    "        'var': numpy.var, 'final': lambda res: res[-1]\n",
    "    }\n",
    "\n",
    "    def __init__(self, data, parameters):\n",
    "        self.data = data\n",
    "        self.visible = False\n",
    "        self.parameters = parameters\n",
    "\n",
    "    def feature_extractor(self, species, results=None, key='final', verbose=False):\n",
    "        if results is None:\n",
    "            results = self.data.values()\n",
    "        data = [[self.func_map[key](traj[species]) for traj in result] for result in results]\n",
    "        if verbose:\n",
    "            print(f'{key} populations for {species}: {data}')\n",
    "        return numpy.array(data)\n",
    "\n",
    "    def ensemble_aggregator(self, results, key='avg', verbose=False):\n",
    "        data = [self.func_map[key](result) for result in results]\n",
    "        if verbose:\n",
    "            print(f'{key} of the ensembles: {data}')\n",
    "        return numpy.array(data)\n",
    "    \n",
    "    def plot(self, species, fe_key='final', ea_key='avg', verbose=False):\n",
    "        x_data = self.parameters[0]['range']\n",
    "        y_data = self.parameters[1]['range']\n",
    "        fe_data = self.feature_extractor(species, key=fe_key, verbose=verbose)\n",
    "        ea_data = self.ensemble_aggregator(fe_data, key=ea_key, verbose=verbose)\n",
    "        shape = (len(self.parameters[1]['range']), len(self.parameters[0]['range']))\n",
    "        data = numpy.flip(numpy.reshape(ea_data, shape))\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(16, 2 * len(data)))\n",
    "        plt.imshow(data)\n",
    "        ax.set_xticks(numpy.arange(data.shape[1]) + 0.5, minor=False)\n",
    "        ax.set_yticks(numpy.arange(data.shape[0]) + 0.5, minor=False)\n",
    "        plt.title(f'Parameter Sweep - Variable: {species}', fontsize=18, fontweight='bold')\n",
    "        ax.set_xticklabels(x_data)\n",
    "        ax.set_yticklabels(y_data)\n",
    "        ax.set_xlabel(self.parameters[1]['param'], fontsize=16, fontweight='bold')\n",
    "        ax.set_ylabel(self.parameters[0]['param'], fontsize=16, fontweight='bold')\n",
    "        ax.tick_params(axis='x', labelsize=14, labelrotation=90)\n",
    "        ax.tick_params(axis='y', labelsize=14)\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "        _ = plt.colorbar(ax=ax, cax=cax)\n",
    "\n",
    "    def plotplotly(self, species, fe_key='final', ea_key='avg',\n",
    "                        return_plotly_figure=False, verbose=False):\n",
    "        x_data = self.parameters[1]['range']\n",
    "        y_data = self.parameters[0]['range']\n",
    "        fe_data = self.feature_extractor(species, key=fe_key, verbose=verbose)\n",
    "        ea_data = self.ensemble_aggregator(fe_data, key=ea_key, verbose=verbose)\n",
    "        shape = (len(self.parameters[1]['range']), len(self.parameters[0]['range']))\n",
    "        data = numpy.reshape(ea_data, shape)\n",
    "\n",
    "        trace_list = [go.Heatmap(z=data, x=x_data, y=y_data)]\n",
    "\n",
    "        title = f'<b>Parameter Sweep - Variable: {species}</b>'\n",
    "        layout = go.Layout(\n",
    "            title=dict(text=title, x=0.5),\n",
    "            xaxis=dict(title=f'<b>{self.parameters[1][\"param\"]}</b>'),\n",
    "            yaxis=dict(title=f'<b>{self.parameters[0][\"param\"]}</b>')\n",
    "        )\n",
    "\n",
    "        fig = dict(data=trace_list, layout=layout)\n",
    "        if return_plotly_figure:\n",
    "            return fig\n",
    "        iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(psweep):\n",
    "    return psweep.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"opioid_data.csv\", 'w', encoding='UTF8', newline = \"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        row = [\"runtime\", 'alpha', 'epsilon', 'beta_p', 'beta_a', 'gamma', 'zeta', 'delta', 'sigma', 'mu', 'mu_prime', \"number_of_trajectories\", \"Timespan\"]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras = ['alpha', 'epsilon', 'beta_p', 'beta_a', 'gamma', 'zeta', 'delta', 'sigma', 'mu', 'mu_prime']\n",
    "ps = []\n",
    "for t in range(100,201,100):\n",
    "    model = create_opioid(t)\n",
    "    for k in (1,3):\n",
    "        kwargs = configure_simulation(model, k)\n",
    "        psweep = ParameterSweep(t, kwargs, model)\n",
    "        for i, para in enumerate(paras):\n",
    "            p_bounds = (\n",
    "            0.9 * float(eval(model.get_parameter(para).expression)),\n",
    "            1.1 * float(eval(model.get_parameter(para).expression))\n",
    "            )\n",
    "            psweep.add_parameter(para, bounds=p_bounds, steps=3)\n",
    "\n",
    "        ps.append(psweep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = client.map(run, psweep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6feb034df6394af58ffecc3d8e63da7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progress(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
